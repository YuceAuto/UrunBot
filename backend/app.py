import os
import time
import logging
from concurrent.futures import ThreadPoolExecutor

from dotenv import load_dotenv
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from rapidfuzz import fuzz

from openai import OpenAI

from image_paths import images  # Our pre-populated ImagePaths instance

load_dotenv()

class ChatbotAPI:
    def __init__(self, openai_key=None):
        """
        ChatbotAPI class manages OpenAI's API,
        handles user requests via Flask,
        includes logic for assistant selection,
        and loads images if needed.
        """
        # 1. Load the OpenAI API key
        self.openai_key = openai_key or os.environ.get("OPENAI_API_KEY", "")
        if not self.openai_key:
            raise ValueError("No OpenAI API key provided. Please set OPENAI_API_KEY as an environment variable.")

        # 2. Initialize the OpenAI client
        self.client = OpenAI(api_key=self.openai_key)

        # 3. Set up logging
        logging.basicConfig(level=logging.WARNING)
        self.logger = logging.getLogger(__name__)

        # 4. Create the Flask application
        self.app = Flask(__name__)
        CORS(self.app)

        # 5. Use the pre-populated ImagePaths instance
        self.image_storage = images
        self.logger.warning("Loading images...")
        for image_name in self.image_storage.list_images():
            self.logger.warning(f"Loaded image: {image_name}")

        # 6. Assistant configuration
        self.ASSISTANT_CONFIG = {
            "asst_1qGG7y8w6QcupPETaYQRdGsI": ["Kamiq"],  # Skoda Kamiq Bot
            "asst_yeDl2aiHy0uoGGjHRmr2dlYB": ["Fabia"],  # Skoda Fabia Bot
            "asst_njSG1NVgg4axJFmvVYAIXrpM": ["Scala"],  # Skoda Scala Bot
        }
        self.RELEVANT_KEYWORDS = ["Kamiq", "Fabia", "Scala"]

        # 7. Track the active assistant
        self.active_assistant_id = None

        # 8. Cache for storing last answers
        self.last_answers = {}  # Format: {assistant_id: "last response"}

        # 9. Define routes
        self._define_routes()

    def _define_routes(self):
        @self.app.route("/", methods=["GET"])
        def home():
            return "Chatbot API is running. Please POST your questions to the /ask endpoint."

        @self.app.route("/ask", methods=["POST"])
        def ask():
            return self._handle_ask_route()

        @self.app.route("/last_answers", methods=["GET"])
        def get_last_answers():
            """
            Endpoint to retrieve the last answers from all assistants.
            """
            return jsonify(self.last_answers)
        # Add this to your route definitions in the backend
        @self.app.route('/static/<path:path>')
        def serve_static_file(path):
            return send_from_directory('static', path)

    def _handle_ask_route(self):
        """
        Main logic for /ask route (user question).
        """
        data = request.json or {}
        user_message = data.get("question", "")
        if not user_message:
            return jsonify({"response": "L√ºtfen bir soru girin."})

        self.logger.warning(f"Kullanƒ±cƒ± mesajƒ±: {user_message}")
        relevant_keywords = ["kamiq", "scala", "fabia"]

        # Find the most similar image name with a higher threshold
        best_match = None
        best_score = 0
        for image_name in self.image_storage.list_images():
            similarity = self._calculate_similarity(user_message, image_name)
            if similarity > best_score and similarity >= 85:  # Adjust threshold if needed
                best_match = {"name": image_name, "path": self.image_storage.get_image(image_name)}
                best_score = similarity

        if best_match:
            return jsonify({
                "response": f"E≈üle≈üen resim bulundu: {best_match['name']}",
                "images": [best_match]
        })
        # If any similar images are found, include them in the response
        if best_match:
            return jsonify({"response": "E≈üle≈üen resimler bulundu.", "images": best_match})

        # If no relevant keyword is found and no assistant is active
        if not any(k.lower() in user_message.lower() for k in relevant_keywords):
            if not self.active_assistant_id:
                self.logger.warning("Anahtar kelime bulunamadƒ±. Daha fazla detay istendi.")
                return jsonify({"response": "Talebinizi daha detaylƒ± girerseniz size yardƒ±mcƒ± olabilirim."})
            # If an assistant is already active
            self.logger.warning(f"Aktif asistan: {self.active_assistant_id}. Aynƒ± asistandan yanƒ±t alƒ±nƒ±yor.")
            _, response = self.process_assistant(self.active_assistant_id, user_message)
            return jsonify({"response": response})

        # If user_message contains a relevant keyword, see if we match a known assistant
        for assistant_id, keywords in self.ASSISTANT_CONFIG.items():
            if any(k.lower() in user_message.lower() for k in keywords):
                self.active_assistant_id = assistant_id
                self.logger.warning(f"Direkt olarak {assistant_id} asistanƒ±na y√∂nlendiriliyor.")
                _, response = self.process_assistant(assistant_id, user_message)
                return jsonify({"response": response})

        # If no direct assistant matched; fallback to previously active
        if self.active_assistant_id:
            self.logger.warning(f"Aktif asistan: {self.active_assistant_id}. Aynƒ± asistandan yanƒ±t alƒ±nƒ±yor.")
            _, response = self.process_assistant(self.active_assistant_id, user_message)
            return jsonify({"response": response})

        # Parallel fallback if no assistant is active
        with ThreadPoolExecutor(max_workers=len(self.ASSISTANT_CONFIG)) as executor:
            results = list(
                executor.map(lambda aid: self.process_assistant(aid, user_message),
                             self.ASSISTANT_CONFIG.keys())
            )

        # Find a relevant answer
        for assistant_id, content in results:
            if content:
                self.active_assistant_id = assistant_id
                self.logger.warning(
                    f"Asistan {assistant_id} i√ßin anahtar kelimeler: "
                    f"{self.ASSISTANT_CONFIG.get(assistant_id, [])}"
                )
                return jsonify({"response": content})

        self.logger.warning("Hi√ßbir asistan uygun bir yanƒ±t veremedi.")
        return jsonify({"response": "Hi√ßbir asistan uygun bir yanƒ±t veremedi."})

    def process_assistant(self, assistant_id, user_message):
        """
        Query the specified assistant with user_message
        and return (assistant_id, response) if relevant, else (assistant_id, None).
        """
        try:
            self.logger.warning("cevap yanƒ±tlanƒ±yor...")

            # Create a thread for conversation
            thread = self.client.beta.threads.create(
                messages=[{"role": "user", "content": user_message}]
            )
            self.logger.warning(f"üëâ Thread Created (Assistant: {assistant_id}): {thread.id}")

            # Start the run
            run = self.client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)
            self.logger.warning(f"üëâ Run Started (Assistant: {assistant_id}): {run.id}")

            # Wait until completion or timeout
            start_time = time.time()
            run_status = "queued"
            while run_status != "completed":
                if time.time() - start_time > 30:  # 10-second timeout
                    raise TimeoutError(f"Timeout for assistant {assistant_id}.")
                run = self.client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
                run_status = run.status
                time.sleep(0.1)

            # Retrieve all messages from the thread
            msg_resp = self.client.beta.threads.messages.list(thread_id=thread.id)
            messages = msg_resp.data
            latest_msg = next((m for m in messages if m.role == "assistant"), None)

            if latest_msg and latest_msg.content:
                content = latest_msg.content
                # If content is a list (rare in some responses), join it
                if isinstance(content, list):
                    content_text = " ".join(str(c) for c in content)
                else:
                    content_text = str(content)

                # Save to last_answers cache
                self.last_answers[assistant_id] = content_text

                return assistant_id, content_text

            return assistant_id, None

        except Exception as e:
            self.logger.error(f"‚ùó Error (Assistant: {assistant_id}): {str(e)}")
            return assistant_id, None

    def _calculate_similarity(self, input_text, image_name):
        """
        Calculate similarity between the user input and an image name using a better algorithm.
        Uses RapidFuzz for fuzzy matching.
        """
        return fuzz.token_sort_ratio(input_text.lower(), image_name.lower())

    def run(self, debug=True):
        """
        Run the Flask application.
        """
        self.app.run(debug=debug)


if __name__ == "__main__":
    chatbot_api = ChatbotAPI()
    chatbot_api.run(debug=True)
